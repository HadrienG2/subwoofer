[workspace]
members = [
    "addsub",
    "average",
    "common",
    "fma_addend_average",
    "fma_full_average",
    "fma_multiplier_average",
    "mul_average",
    "sqrt_positive_addsub"
]

[workspace.package]
version = "0.1.0"
edition = "2021"

[package]
name = "subwoofer"
version.workspace = true
edition.workspace = true

[features]
# If you are running this benchmark on hardware which you only have temporary
# access to, consider --all-features to check everything that the benchmark can
# possibly measure, at the expense of extremely long compilation and execution
# time (we're talking about multiple days of execution).
#
# More fine-grained options are described below.
default = ["check"]

# Run just enough benchmarks to tell which hardware operations are affected by
# subnormals, but not to precisely quantify how much they are affected and which
# input configurations affects them. Use the "measure" feature if you are
# interested in measuring that.
check = [
    "bench_addsub",               # ADD/SUB
    "bench_sqrt_positive_addsub", # Includes SQRT
    "bench_mul_average",          # Includes MUL
    "bench_fma_full_average",     # Includes FMA
]

# Enable this feature when you want to precisely know when hardware operations
# are affected by subnormals, and how bad the impact can get.
#
# The price to pay is a large increase in compilation and execution time.
measure = [
    "bench_all",
    "register_data_sources",
    "simd",
    "subnormal_freq_resolution_1in64",
]

# Full set of supported microbenchmarks
bench_all = [
    "bench_addsub",                  # ADD/SUB with x%subnormal input, normal result
    "bench_sqrt_positive_addsub",    # addsub + SQRT with x%subnormal input & result
    "bench_average",                 # ADD x%subnormal -> MUL, subtract from following
    "bench_mul_average",             # average + MUL with x%subnormal input & result
    "bench_fma_multiplier_average",  # average + FMA with x%subnormal multiplier, normal addend & result
    "bench_fma_addend_average",      # average + FMA with x%subnormal addend, normal multiplier & result
    "bench_fma_full_average",        # average + FMA with x%subnormal multiplier and addend, x²%subnormal result
]

# Control which benchmarks are built in a fine-grained ways. Lets you speed up
# compilation when debugging one benchmark. Use with --no-default-features.
bench_addsub = ["dep:addsub"]
bench_average = ["dep:average"]
bench_fma_addend_average = ["dep:fma_addend_average"]
bench_fma_full_average = ["dep:fma_full_average"]
bench_fma_multiplier_average = ["dep:fma_multiplier_average"]
bench_mul_average = ["dep:mul_average"]
bench_sqrt_positive_addsub = ["dep:sqrt_positive_addsub"]

# By default, we only run benchmarks from data in the L1 cache, because that's
# where we expect the maximal subnormal impact outside of perhaps the
# in-registers configuration, and it's less artificial and less likely to be
# messed up by CPU µarch details than the in-registers configuration.
#
# Use this feature to test at all levels of the memory hierarchy instead, at the
# expense of a large increase in compilation and execution time...
more_data_sources = ["register_data_sources", "more_memory_data_sources"]

# ...or use these finer-grained features if you want to be more specific
register_data_sources = []
more_memory_data_sources = []

# By default, we only run benchmarks with no instruction-level parallelism
# (always latency-bound), with ~maximal ILP (hopefully throughput-bound), and
# with half the maximal ILP (as a sanity check, see below).
#
# This feature lets you cover all power-of-two degrees of ILP instead. Use it
# when you observe that the intermediate ILP configuration runs faster than the
# maximal ILP configuration, which suggests that the maximal ILP configuration
# is running into a microarchitectural bottleneck e.g. it trashes the CPU's
# instruction cache because there is too much code. In this situation, it is
# better to try all ILP configurations to make sure that you do cover the ILP
# configuration of highest runtime performance.
#
# The price to pay is a moderate increase in execution time.
more_ilp_configurations = []

# By default, we only check subnormal behavior in scalars.
#
# Enable this feature to also check vectors of all-normals or all-subnormals.
# This lets you check if the subnormal fallback logic is vectorized or scalar.
#
# The price to pay is a large increase in compilation and execution time.
simd = []

# By default, we check with [0, 25, 50, 75, 100]% of subnormal inputs.
#
# If you notice that the subnormals-induced slowdown does not follow a simple
# monotonic pattern (e.g. linearly grows to a maximum at 100%, or linearly grows
# from 0% to 50% then linearly decays from 50% to 100%), then you should try
# enabling one of the following features to more precisely probe the overhead vs
# subnormal occurence frequency curve.
#
# The suggested way to tune this for your hardware, if you have enough time, is:
#
# 1. Start with the maximal supported resolution configuration.
# 2. Check out the criterion report, find out how many data point you truly need
#    to faithfully probe the overhead vs subnormals frequency curve (e.g. to
#    sample the maximal overhead point with good precision).
# 3. If you need to re-run the benchmark on the same hardware later on, use only
#    this number of data points to reduce execution time.
#
# The price to pay for increasing subnormal frequency resolution is a
# multiplicative increase in execution time on benchmarks with memory inputs.
subnormal_freq_resolution_1in8 = []
subnormal_freq_resolution_1in16 = []
subnormal_freq_resolution_1in32 = []
subnormal_freq_resolution_1in64 = []
subnormal_freq_resolution_1in128 = []
# TODO: Add configurations and adjust "measure" configuration if we find
#       hardware where <1% resolution is still not enough

[workspace.dependencies]
common = { path = "./common" }
criterion = "0.5"
pessimize = { version = "2.0", features = ["nightly"] }
rand = "0.8.5"
target-features = "0.1"
hwlocality = "1.0.0-alpha"

[dependencies]
addsub = { path = "./addsub", optional = true }
average = { path = "./average", optional = true }
fma_addend_average = { path = "./fma_addend_average", optional = true }
fma_full_average = { path = "./fma_full_average", optional = true }
fma_multiplier_average = { path = "./fma_multiplier_average", optional = true }
mul_average = { path = "./mul_average", optional = true }
sqrt_positive_addsub = { path = "./sqrt_positive_addsub", optional = true }

[dev-dependencies]
common.workspace = true
criterion.workspace = true
hwlocality.workspace = true
rand.workspace = true

[lib]
bench = false

[[bench]]
name = "benchmark"
harness = false

[profile.release]
# Good for perf profiling
debug = "line-tables-only"
# Sadly needed for pessimize::hide() to be compiled efficiently. Without it, no
# amount of inlining and LTO can save rustc nightly 2024-12-06 from spilling
# accumulators to memory in benchmarks with memory data sources. It is not clear
# to me why that is the case, most likely multiple codegen units get in the way
# of an important whole-program optimization.
codegen-units = 1
